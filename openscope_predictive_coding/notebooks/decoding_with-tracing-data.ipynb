{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#Misc\n",
    "import time, os, sys, pdb\n",
    "from glob import glob\n",
    "from fnmatch import fnmatch\n",
    "\n",
    "#Base\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from multiprocessing import Pool\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Save\n",
    "import json, h5py\n",
    "import scipy.io as sio\n",
    "\n",
    "#Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "#Predictive Coding Github Repository\n",
    "sys.path.append('/home/dwyrick/Git/openscope_predictive_coding/')\n",
    "from openscope_predictive_coding.ophys.dataset.openscope_predictive_coding_dataset import OpenScopePredictiveCodingDataset\n",
    "from openscope_predictive_coding.ophys.response_analysis.response_analysis import ResponseAnalysis\n",
    "\n",
    "#User\n",
    "import openscope_predictive_coding.ophys.decoding_analysis.decoding as dc\n",
    "import openscope_predictive_coding.ophys.response_analysis.utilities as openscope_utils\n",
    "\n",
    "#Params\n",
    "mainseq_ids = [68, 78, 13, 26]\n",
    "oddball_ids = [6, 17, 22, 51, 71, 89, 103, 110, 111, 112]\n",
    "all_ids = np.concatenate((mainseq_ids,oddball_ids))\n",
    "SaveDir = '/home/dwyrick/projects/predictive_coding/results/decoding/'\n",
    "PlotDir = os.path.join(SaveDir,'plots')\n",
    "\n",
    "areanames = ['VISp', 'VISpm','RSP']\n",
    "mainseq_labels = ['A','B','C','D']\n",
    "blocknames = ['randomized_control_pre','oddball','transition_control','randomized_control_post']\n",
    "stimulus_blocks = ['randomized_control_pre','oddball','transition_control','randomized_control_post']\n",
    "blocklabels = ['Rand-Ctrl-Pre', 'Oddball', 'Trans-Ctrl', 'Rand-Ctrl-Post']\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "color_names=['windows blue',\n",
    "             'red',\n",
    "             'amber',\n",
    "             'faded green',\n",
    "             'dusty purple',\n",
    "             'orange',\n",
    "             'steel blue',\n",
    "             'pink',\n",
    "             'greyish',\n",
    "             'mint',\n",
    "             'clay',\n",
    "             'light cyan',\n",
    "             'forest green',\n",
    "             'pastel purple',\n",
    "             'salmon',\n",
    "             'dark brown',\n",
    "             'lavender',\n",
    "             'pale green',\n",
    "             'dark red',\n",
    "             'gold',\n",
    "             'dark teal',\n",
    "             'rust',\n",
    "             'fuchsia',\n",
    "             'pale orange',\n",
    "             'cobalt blue',\n",
    "             'mahogany',\n",
    "             'cloudy blue',\n",
    "             'dark pastel green',\n",
    "             'dust',\n",
    "             'electric lime',\n",
    "             'fresh green',\n",
    "             'light eggplant',\n",
    "             'nasty green']\n",
    " \n",
    "color_palette = sns.xkcd_palette(color_names)\n",
    "cc = sns.xkcd_palette(color_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dwyrick/projects/predictive_coding'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data streams for each imaging session are saved as .h5 files in each folder's experiment in this directory\n",
    "cache_dir = '/srv/data/AllenInst/opc_analysis'\n",
    "\n",
    "# Read in experiment manifest\n",
    "manifest_file = '/srv/data/AllenInst/opc_analysis/opc_production_manifest.xlsx'\n",
    "manifest = pd.read_excel(manifest_file)\n",
    "\n",
    "# limit to experiments that passed QC\n",
    "manifest = manifest[manifest['experiment_state']=='passed']\n",
    "areanames = np.unique(manifest['imaging_area'])\n",
    "\n",
    "data = sio.loadmat('/home/dwyrick/projects/predictive_coding/data/preferredStim.mat')\n",
    "preferred_imageIDs = data['preferred_imageIDs'][0]\n",
    "cellIDs = data['cellIDs'][0]\n",
    "\n",
    "cell_metadata_df = pd.read_csv('/home/dwyrick/projects/predictive_coding/data/cell_metadata.csv')\n",
    "cell_metadata_df.drop(columns='Unnamed: 0',inplace=True)\n",
    "cell_metadata_df.drop_duplicates(subset='cell_specimen_id',inplace=True)\n",
    "cell_metadata_df.set_index('cell_specimen_id', drop=True, inplace=True)\n",
    "\n",
    "\n",
    "pIDs = []\n",
    "for cellID in cell_metadata_df.index.values:\n",
    "    \n",
    "    indy = np.where(cellIDs == cellID)[0][0]\n",
    "    pID = preferred_imageIDs[indy]\n",
    "    pIDs.append(pID)\n",
    "    \n",
    "cell_metadata_df['pref_stim'] = pIDs\n",
    "\n",
    "os.chdir('/home/dwyrick/projects/predictive_coding')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate data from all experiments to create pseudopopulation response arrays\n",
    "# This cell takes a while to run, which is why I've split up the functions of getting the data and selecting the data we want to decode with\n",
    "variable = 'summed_response'\n",
    "use_events = True\n",
    "pseudopop_responses = {b: {} for b in stimulus_blocks}\n",
    "areanames = ['VISp', 'VISpm','RSP']\n",
    "for block_str in stimulus_blocks:\n",
    "    processes = []\n",
    "    with Pool(20) as p: \n",
    "        for area in areanames:\n",
    "            processes.append(p.apply_async(dc.create_psuedopopulation,args=(manifest,area,block_str,use_events,variable)))\n",
    "\n",
    "        for area, out in zip(areanames,processes):\n",
    "            X, stimulus_df = out.get()\n",
    "            pseudopop_responses[block_str][area] = X \n",
    "                        \n",
    "# for area, sub_list in zip(areanames,processes):\n",
    "#     for blockstr, result in zip(stimulus_blocks,sub_list):\n",
    "#         X, stimulus_df = result.get()\n",
    "#         pseudopop_responses[blockstr][area] = X \n",
    "# pool.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing decoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "randctrl_labeled_rsponses = {'FF': {},'FB': {}}\n",
    "transctrl_labeled_rsponses = {'FF': {},'FB': {}}\n",
    "oddball_labeled_rsponses = {'FF': {},'FB': {}}\n",
    "\n",
    "for ii, area in enumerate(areanames):\n",
    "    #Loop over depth as well\n",
    "    for jj,depthstr in enumerate(['superficial','deep']):\n",
    "        locstr = '{}_{}'.format(area,depthstr)\n",
    "        cell_ids_perdepth_FF = cell_metadata_df[(cell_metadata_df['location'] == locstr) & (cell_metadata_df['retrogradely_labeled'] == True) & (cell_metadata_df['projection_pathway'] == 'FF')].index.values\n",
    "        \n",
    "        if len(cell_ids_perdepth_FF) > 0:\n",
    "            randctrl_labeled_rsponses['FF'][locstr] = [randctrl_pseudopop_responses[area][0].loc[:,cell_ids_perdepth_FF], randctrl_pseudopop_responses[area][1].loc[:,cell_ids_perdepth_FF]]\n",
    "            transctrl_labeled_rsponses['FF'][locstr] = transctrl_pseudopop_responses[area].loc[:,cell_ids_perdepth_FF]\n",
    "            oddball_labeled_rsponses['FF'][locstr] = oddball_pseudopop_responses[area].loc[:,cell_ids_perdepth_FF]\n",
    "           \n",
    "        cell_ids_perdepth_FB = cell_metadata_df[(cell_metadata_df['location'] == locstr) & (cell_metadata_df['retrogradely_labeled'] == True) & (cell_metadata_df['projection_pathway'] == 'FB')].index.values\n",
    "        if len(cell_ids_perdepth_FB) > 0:\n",
    "            randctrl_labeled_rsponses['FB'][locstr] = [randctrl_pseudopop_responses[area][0].loc[:,cell_ids_perdepth_FB], randctrl_pseudopop_responses[area][1].loc[:,cell_ids_perdepth_FB]]\n",
    "            transctrl_labeled_rsponses['FB'][locstr] = transctrl_pseudopop_responses[area].loc[:,cell_ids_perdepth_FB]\n",
    "            oddball_labeled_rsponses['FB'][locstr] = oddball_pseudopop_responses[area].loc[:,cell_ids_perdepth_FB]\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Let's decode stimulus blocks from each other based on responses to MS images\n",
    "\n",
    "method='kfold'\n",
    "PlotDir = os.path.join(SaveDir,'plots')\n",
    "\n",
    "nClasses = 4\n",
    "#Get off diagonal indices\n",
    "upper_tmp = np.triu_indices(nClasses,k=1)\n",
    "lower_tmp = np.tril_indices(nClasses,k=-1)\n",
    "off_diagonal_indy = (np.concatenate((upper_tmp[0],lower_tmp[0])),np.concatenate((upper_tmp[1],lower_tmp[1])))\n",
    "\n",
    "\n",
    "\n",
    "classifier = 'nearest_neighbor'\n",
    "SaveDir = '/home/dwyrick/projects/predictive_coding/results/decoding/pseudopopulation'\n",
    "fstr = 'pseudopop'\n",
    "PlotDir = os.path.join(SaveDir,'plots')\n",
    "\n",
    "\n",
    "\n",
    "# fig2, axes2 = plt.subplots(2,3,figsize=(12,8),gridspec_kw={'hspace':0.35},sharey/=True,sharex=True)\n",
    "\n",
    "for tracing in ['FF','FB']:\n",
    "    for ii, area in enumerate(areanames):\n",
    "        cell_ids = oddball_pseudopop_responses[area].coords['cell_specimen_id'].values\n",
    "\n",
    "        #Loop over depth as well\n",
    "        for jj,depthstr in enumerate(['superficial','deep']):\n",
    "            locstr = '{}_{}'.format(area,depthstr)\n",
    "            if locstr not in oddball_labeled_rsponses[tracing].keys():\n",
    "                continue\n",
    "                \n",
    "            #Get data for this area\n",
    "            X_randctrl_pre, Y_randctrl_pre, _ = dc.match_trials(randctrl_labeled_rsponses[tracing][locstr][0], stimulus_df, block='randomized_control_pre', trial_type='ABCD')\n",
    "            X_oddball, Y_oddball, _ = dc.match_trials(oddball_labeled_rsponses[tracing][locstr], stimulus_df, block='oddball', trial_type='ABCD',trial_indy=slice(740,860))\n",
    "            X_transctrl, Y_transctrl, _ = dc.match_trials(transctrl_labeled_rsponses[tracing][locstr], stimulus_df, block='transition_control', trial_type='ABCD')\n",
    "            X_randctrl_post, Y_randctrl_post, _ = dc.match_trials(randctrl_labeled_rsponses[tracing][locstr][1], stimulus_df, block='randomized_control_post', trial_type='ABCD')\n",
    "\n",
    "            confusion_mat = np.zeros((4,nClasses,nClasses))\n",
    "            confusion_shf = np.zeros((4,nClasses,nClasses))\n",
    "            confusion_z = np.zeros((4,nClasses,nClasses))\n",
    "\n",
    "            nNeurons = X_randctrl_pre.shape[-1]\n",
    "            for iImg, img_ID in enumerate(mainseq_ids):\n",
    "                #Get stimulus presentation IDs for this particular image from both blocks\n",
    "                indy_pre = np.where(Y_randctrl_pre == img_ID)[0]\n",
    "                indy_oddball = np.where(Y_oddball == img_ID)[0]\n",
    "                indy_transctrl = np.where(Y_transctrl == img_ID)[0]\n",
    "                indy_post = np.where(Y_randctrl_post == img_ID)[0]\n",
    "\n",
    "                #Construct X and Y from both blocks\n",
    "                X = np.vstack((X_randctrl_pre[indy_pre,:],X_oddball[indy_oddball,:],X_transctrl[indy_transctrl,:],X_randctrl_post[indy_post,:]))\n",
    "                Y = np.hstack([np.repeat(i,30) for i in range(nClasses)])\n",
    "\n",
    "                confusion_mat[iImg], confusion_shf[iImg], confusion_z[iImg] = dc.cross_validate(X,Y,clabels=[0,1,2,3],classifier=classifier,method=method,plot_shuffle=False,parallel=False)\n",
    "\n",
    "#     #                 pdb.set_trace()\n",
    "#             fpath = os.path.join(SaveDir,'StimulusBlocks_MSimgs_{}_{}_{}_{}.mat'.format(locstr,fstr,method,classifier))\n",
    "#             with h5py.File(fpath,'w') as h5file:\n",
    "#                 h5file.create_dataset('confusion_mat',data=confusion_mat)\n",
    "#                 h5file.create_dataset('confusion_shf',data=confusion_shf)\n",
    "#                 h5file.create_dataset('confusion_z',data=confusion_z)\n",
    "#                 h5file.create_dataset('area',data=area)\n",
    "#                 h5file.create_dataset('classifier',data=classifier)\n",
    "#                 h5file.create_dataset('method',data=method)\n",
    "\n",
    "            #Plot shuffle distributions\n",
    "            dc.plot_confusion_matrices(confusion_mat,confusion_z,plot_titles=['A','B','C','D'],class_labels=['rand-pre','OB', 'Trans','rand-post'])\n",
    "            plt.suptitle('Classifying Stimulus Condition for area {}, {} neurons'.format(locstr, tracing),y=0.95)\n",
    "#             plt.savefig(os.path.join(PlotDir,'StimulusBlocks_avg-over-ms_{}_{}_{}_{}_{}.png'.format(tracing,fstr,locstr,method,classifier)))\n",
    "\n",
    "#             #Sparate diagonal and off-diagonal performance\n",
    "#             diag_hits = np.concatenate([np.diag(confusion_mat[i]) for i in range(len(mainseq_ids))])\n",
    "\n",
    "#             offdiag_hits = []\n",
    "#             for iImg in range(len(mainseq_ids)):\n",
    "#                 cm = confusion_mat[iImg]\n",
    "#                 cm[np.diag_indices(nClasses)] = np.nan\n",
    "#                 offdiag_hits.extend([np.nanmean(cm[i,:]) for i in range(nClasses)]);\n",
    "\n",
    "#             _, pval = st.wilcoxon(diag_hits,offdiag_hits)\n",
    "#             ax = axes2[jj,ii]\n",
    "#             ax.set_title(f'{locstr}')\n",
    "#             ax.boxplot([diag_hits,offdiag_hits])\n",
    "#             if pval < pval_thresh:\n",
    "#                 ax.hlines(1,*[1,2],color='k',zorder=0)\n",
    "#                 ax.vlines(2,*[1,.95],color='k',zorder=0) \n",
    "#                 ax.vlines(1,*[1,.95],color='k',zorder=0)\n",
    "#                 ax.text(1.4,.975,'*',fontdict={'fontweight':'bold','fontsize': 28,'color': 'k'})\n",
    "\n",
    "#             ax.set_ylim([-0.15,1.15])\n",
    "#             if jj == 1:\n",
    "#                 ax.set_xticks([1,2])\n",
    "#                 ax.set_xticklabels(['Hits','Off-Diag'])\n",
    "#             if ii == 0:\n",
    "#                 ax.set_ylabel('Decoding\\n Performance')\n",
    "\n",
    "#     fig2.suptitle('Decoding Between all Stimulus Contexts \\nusing responses to main-sequence images',y=0.995)\n",
    "# #     fig2.savefig(os.path.join(PlotDir,'StimulusBlocks_BOXPLOT_{}_{}_{}.png'.format(fstr,method,classifier)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#In the transition control, there are 30 trials per transition type. so, there are 30 trials where DA are presented in series and 30 trials where DX are presented per oddball\n",
    "#So, given the # of trials per transition type, I created a decoder for each XA type, keeping the DA trials the same\n",
    "method='L1O'\n",
    "\n",
    "classifier = 'nearest_neighbor'\n",
    "SaveDir = '/home/dwyrick/projects/predictive_coding/results/decoding/pseudopopulation'\n",
    "fstr = 'pseudopop'\n",
    "PlotDir = os.path.join(SaveDir,'plots')\n",
    "\n",
    "\n",
    "nClasses = 2\n",
    "for tracing in ['FF','FB']:\n",
    "    for area in areanames:\n",
    "        cell_ids = transctrl_pseudopop_responses[area].coords['cell_specimen_id'].values\n",
    "\n",
    "        #Loop over depth as well\n",
    "        for depthstr in ['superficial','deep']:\n",
    "            locstr = '{}_{}'.format(area,depthstr)\n",
    "            if locstr not in oddball_labeled_rsponses[tracing].keys():\n",
    "                continue\n",
    "\n",
    "            #Get data for this area\n",
    "            X_oddball, Y_oddball, Y_sort = dc.match_trials(oddball_labeled_rsponses[tracing][locstr], stimulus_df, block='oddball', trial_type='DAXA')\n",
    "            X_transctrl, Y_transctrl, Y_sort = dc.match_trials(transctrl_labeled_rsponses[tracing][locstr], stimulus_df, block='transition_control', trial_type='DAXA')\n",
    "            nNeurons = X_transctrl.shape[-1]\n",
    "            confusion_mat = np.zeros((len(oddball_ids),2,2))\n",
    "            confusion_shf = np.zeros((len(oddball_ids),2,2))\n",
    "            confusion_z = np.zeros((len(oddball_ids),2,2))\n",
    "\n",
    "            for iImg, img_ID in enumerate(oddball_ids):\n",
    "                #Get stimulus presentation IDs for this particular image from both blocks\n",
    "                indy_DA = np.where(Y_sort == mainseq_ids[0])[0]\n",
    "                indy_XA = np.where(Y_sort == img_ID)[0]\n",
    "\n",
    "                #Construct X and Y from both blocks\n",
    "                X = np.vstack((X_transctrl[indy_DA,:],X_transctrl[indy_XA,:]))\n",
    "                Y = np.hstack((np.repeat(0,len(indy_DA)),np.repeat(1,len(indy_XA))))\n",
    "\n",
    "                confusion_mat[iImg], confusion_shf[iImg], confusion_z[iImg] = dc.cross_validate(X,Y,clabels=[0,1],classifier=classifier,method=method)\n",
    "\n",
    "    #         fpath = os.path.join(SaveDir,'DAvsXA_TransCtrl-block_{}_{}_{}.mat'.format(locstr,method,classifier))\n",
    "    #         with h5py.File(fpath,'w') as h5file:\n",
    "    #             h5file.create_dataset('confusion_mat',data=confusion_mat)\n",
    "    #             h5file.create_dataset('confusion_shf',data=confusion_shf)\n",
    "    #             h5file.create_dataset('confusion_z',data=confusion_z)\n",
    "    #             h5file.create_dataset('area',data=area)\n",
    "    #             h5file.create_dataset('classifier',data=classifier)\n",
    "    #             h5file.create_dataset('method',data=method)\n",
    "\n",
    "            #Plot shuffle distributions\n",
    "            dc.plot_decoding_accuracy(np.mean(confusion_mat,axis=0),np.mean(confusion_z,axis=0),class_labels=['(D,A)','(X,A)'])\n",
    "\n",
    "            plt.suptitle('Classifying Transition Type\\n Based on image A response; {}, {} {} neurons'.format(locstr,nNeurons,tracing),y=0.925)\n",
    "#         plt.savefig(os.path.join(PlotDir,'DAvsXA_TransCtrl-block_{}_{}_{}.png'.format(locstr,method,classifier)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#In the transition control, there are 30 trials per transition type. so, there are 30 trials where DA are presented in series and 30 trials where DX are presented per oddball\n",
    "#So, given the # of trials per transition type, I created a decoder for each XA type, keeping the DA trials the same\n",
    "method='kfold'\n",
    "\n",
    "classifier = 'SVM'\n",
    "SaveDir = '/home/dwyrick/projects/predictive_coding/results/decoding/pseudopopulation'\n",
    "fstr = 'pseudopop'\n",
    "PlotDir = os.path.join(SaveDir,'plots')\n",
    "\n",
    "\n",
    "nClasses = 2\n",
    "for tracing in ['FF','FB']:\n",
    "    for area in areanames:\n",
    "        cell_ids = transctrl_pseudopop_responses[area].coords['cell_specimen_id'].values\n",
    "\n",
    "        #Loop over depth as well\n",
    "        for depthstr in ['superficial','deep']:\n",
    "            locstr = '{}_{}'.format(area,depthstr)\n",
    "            if locstr not in oddball_labeled_rsponses[tracing].keys():\n",
    "                continue\n",
    "\n",
    "            #Get data for this area\n",
    "            X_oddball, Y_oddball, Y_sort = dc.match_trials(oddball_labeled_rsponses[tracing][locstr], stimulus_df, block='oddball', trial_type='DAXA')\n",
    "#             X_transctrl, Y_transctrl, Y_sort = dc.match_trials(transctrl_labeled_rsponses[tracing][locstr], stimulus_df, block='transition_control', trial_type='DAXA')\n",
    "            nNeurons = X_oddball.shape[-1]\n",
    "#             pdb.set_trace()\n",
    "            confusion_mat, confusion_shf, confusion_z = dc.cross_validate(X_oddball, Y_oddball, Y_sort,nKfold=5,clabels=[0,1],classifier=classifier,method=method)\n",
    "            \n",
    "    #         fpath = os.path.join(SaveDir,'DAvsXA_TransCtrl-block_{}_{}_{}.mat'.format(locstr,method,classifier))\n",
    "    #         with h5py.File(fpath,'w') as h5file:\n",
    "    #             h5file.create_dataset('confusion_mat',data=confusion_mat)\n",
    "    #             h5file.create_dataset('confusion_shf',data=confusion_shf)\n",
    "    #             h5file.create_dataset('confusion_z',data=confusion_z)\n",
    "    #             h5file.create_dataset('area',data=area)\n",
    "    #             h5file.create_dataset('classifier',data=classifier)\n",
    "    #             h5file.create_dataset('method',data=method)\n",
    "\n",
    "            #Plot shuffle distributions\n",
    "            dc.plot_decoding_accuracy(confusion_mat,confusion_z,class_labels=['(D,A)','(X,A)'])\n",
    "\n",
    "            plt.suptitle('Classifying Transition Type\\n Based on image A response; {}, {} {} neurons'.format(locstr,nNeurons,tracing),y=0.925)\n",
    "        plt.savefig(os.path.join(PlotDir,'DAvsXA_Oddball-block_{}_{}_{}_{}.png'.format(tracing,locstr,method,classifier)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "classifier = 'SVM'\n",
    "method='kfold'\n",
    "reduce_dim=False\n",
    "\n",
    "#Get off diagonal indices\n",
    "upper_tmp = np.triu_indices(nClasses,k=1)\n",
    "lower_tmp = np.tril_indices(nClasses,k=-1)\n",
    "off_diagonal_indy = (np.concatenate((upper_tmp[0],lower_tmp[0])),np.concatenate((upper_tmp[1],lower_tmp[1])))\n",
    "    \n",
    "for tracing in ['FF','FB']:\n",
    "    for area in areanames:\n",
    "        cell_ids = transctrl_pseudopop_responses[area].coords['cell_specimen_id'].values\n",
    "\n",
    "        #Loop over depth as well\n",
    "        for depthstr in ['superficial','deep']:\n",
    "            locstr = '{}_{}'.format(area,depthstr)\n",
    "            if locstr not in oddball_labeled_rsponses[tracing].keys():\n",
    "                continue\n",
    "                \n",
    "#             X_randctrl_pre, Y_randctrl_pre, _ = dc.match_trials(randctrl_labeled_rsponses[tracing][locstr][0], stimulus_df, block='randomized_control_pre', trial_type='ABCD')\n",
    "            X_oddball, Y_oddball, _ = dc.match_trials(oddball_labeled_rsponses[tracing][locstr], stimulus_df, block='oddball', trial_type='ABCD',trial_indy=slice(740,1220))\n",
    "#             X_transctrl, Y_transctrl, _ = dc.match_trials(transctrl_labeled_rsponses[tracing][locstr], stimulus_df, block='transition_control', trial_type='ABCD')\n",
    "#             X_randctrl_post, Y_randctrl_post, _ = dc.match_trials(randctrl_labeled_rsponses[tracing][locstr][1], stimulus_df, block='randomized_control_post', trial_type='ABCD')\n",
    "\n",
    "        \n",
    "            X = X_oddball; Y = Y_oddball\n",
    "            nNeurons = X.shape[-1]\n",
    "            print(np.unique(Y,return_counts=True))\n",
    "#             pdb.set_trace()\n",
    "            confusion_mat, confusion_shf, confusion_z = dc.cross_validate(X,Y,clabels=mainseq_ids,nKfold=10,classifier=classifier,method=method)\n",
    "            \n",
    "#             fpath = os.path.join(SaveDir,'mainseq_decoding_{}-block_{}_{}_{}.mat'.format(block_str,locstr,method,classifier))\n",
    "#             with h5py.File(fpath,'w') as h5file:\n",
    "#                 h5file.create_dataset('confusion_mat',data=confusion_mat)\n",
    "#                 h5file.create_dataset('confusion_shf',data=confusion_shf)\n",
    "#                 h5file.create_dataset('confusion_z',data=confusion_z)\n",
    "#                 h5file.create_dataset('area',data=area)\n",
    "#                 h5file.create_dataset('classifier',data=classifier)\n",
    "#                 h5file.create_dataset('method',data=method)\n",
    "\n",
    "            dc.plot_decoding_accuracy(confusion_mat,confusion_z,class_labels=['A','B','C','D'],clims=[0.1,0.4])\n",
    "\n",
    "            plt.suptitle('Classifying MS images for {}, {} {} neurons'.format(locstr, nNeurons, tracing),y=0.925,fontsize=14)\n",
    "            plt.savefig(os.path.join(PlotDir,'mainseq_decoding_oddball-blocks_{}_{}_{}.png'.format(tracing,locstr,classifier)))\n",
    "        \n",
    "#              #Sparate diagonal and off-diagonal performance\n",
    "#             diag_hits = np.diag(confusion_mat)\n",
    "#             offdiag_hits = confusion_mat[off_diagonal_indy]\n",
    "\n",
    "#             axes2[jj,ii].set_title(locstr)\n",
    "#             axes2[jj,ii].boxplot([diag_hits,offdiag_hits])\n",
    "#             if jj == 1:\n",
    "#                 axes2[jj,ii].set_xticks([1,2])\n",
    "#                 axes2[jj,ii].set_xticklabels(['Hits','Off-Diag'])\n",
    "#             if ii == 0:\n",
    "#                 axes2[jj,ii].set_ylabel('Decoding Performance')\n",
    "            \n",
    "#     fig2.suptitle('Classifying MS images for {}, {} classifer'.format(locstr,classifier),y=0.995)\n",
    "#     fig2.savefig(os.path.join(PlotDir,'mainseq_decoding_randctrl-blocks_{}_{}.png'.format(method,classifier)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "classifier = 'nearest_neighbor'\n",
    "\n",
    "method = 'kfold'\n",
    "classifier = 'SVM'\n",
    "fstr = 'pseudopop'\n",
    "PlotDir = os.path.join(SaveDir,'plots')\n",
    "nKfold=10\n",
    "    \n",
    "for tracing in ['FF','FB']:\n",
    "    for area in areanames:\n",
    "        cell_ids = transctrl_pseudopop_responses[area].coords['cell_specimen_id'].values\n",
    "\n",
    "        #Loop over depth as well\n",
    "        for depthstr in ['superficial','deep']:\n",
    "            locstr = '{}_{}'.format(area,depthstr)\n",
    "            if locstr not in oddball_labeled_rsponses[tracing].keys():\n",
    "                continue\n",
    "                \n",
    "#             X_randctrl_pre, Y_randctrl_pre, _ = dc.match_trials(randctrl_labeled_rsponses[tracing][locstr][0], stimulus_df, block='randomized_control_pre', trial_type='ABCD')\n",
    "            X_oddball, Y_oddball, Y_sort = dc.match_trials(oddball_labeled_rsponses[tracing][locstr], stimulus_df, block='oddball', trial_type='ABCDX')\n",
    "#             X_transctrl, Y_transctrl, _ = dc.match_trials(transctrl_labeled_rsponses[tracing][locstr], stimulus_df, block='transition_control', trial_type='ABCD')\n",
    "#             X_randctrl_post, Y_randctrl_post, _ = dc.match_trials(randctrl_labeled_rsponses[tracing][locstr][1], stimulus_df, block='randomized_control_post', trial_type='ABCD')\n",
    "\n",
    "            X = X_oddball; Y = Y_oddball\n",
    "            nNeurons = X.shape[-1]\n",
    "            print(np.unique(Y,return_counts=True))\n",
    "#             pdb.set_trace()\n",
    "            #Use pseudopopulation vectors for decoding\n",
    "            confusion_mat, confusion_shf, confusion_z = dc.cross_validate(X_oddball,Y_oddball,Y_sort,method=method,nKfold=nKfold,classifier=classifier,clabels=[68, 78, 13, 26, 1])\n",
    "\n",
    "    #         fpath = os.path.join(SaveDir,'prevMSvsX_decoding_oddball-block_{}_{}.mat'.format(locstr,classifier))\n",
    "    #         with h5py.File(fpath,'w') as h5file:\n",
    "    #             h5file.create_dataset('confusion_mat',data=confusion_mat)\n",
    "    #             h5file.create_dataset('confusion_shf',data=confusion_shf)\n",
    "    #             h5file.create_dataset('confusion_z',data=confusion_z)\n",
    "    #             h5file.create_dataset('area',data=area)\n",
    "    #             h5file.create_dataset('classifier',data=classifier)\n",
    "    #             h5file.create_dataset('method',data=method)\n",
    "\n",
    "            dc.plot_decoding_accuracy(confusion_mat,confusion_z,class_labels=['A','B','C','D','X'],title=locstr,annot=True)\n",
    "            plt.suptitle('ABCD---X\\n {} {} nNeurons'.format(nNeurons,tracing))\n",
    "            plt.savefig(os.path.join(PlotDir,'prevMSvsX_decoding_oddball-blocks_{}-fold_{}-area_{}neurons.png'.format(nKfold,locstr,tracing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "classifier = 'nearest_neighbor'\n",
    "\n",
    "method = 'kfold'\n",
    "classifier = 'SVM'\n",
    "fstr = 'pseudopop'\n",
    "PlotDir = os.path.join(SaveDir,'plots')\n",
    "nKfold=10\n",
    "    \n",
    "for tracing in ['FF','FB']:\n",
    "    for area in areanames:\n",
    "        cell_ids = transctrl_pseudopop_responses[area].coords['cell_specimen_id'].values\n",
    "\n",
    "        #Loop over depth as well\n",
    "        for depthstr in ['superficial','deep']:\n",
    "            locstr = '{}_{}'.format(area,depthstr)\n",
    "            if locstr not in oddball_labeled_rsponses[tracing].keys():\n",
    "                continue\n",
    "                \n",
    "#             X_randctrl_pre, Y_randctrl_pre, _ = dc.match_trials(randctrl_labeled_rsponses[tracing][locstr][0], stimulus_df, block='randomized_control_pre', trial_type='ABCD')\n",
    "            X_oddball, Y_oddball, Y_sort = dc.match_trials(oddball_labeled_rsponses[tracing][locstr], stimulus_df, block='oddball', trial_type='XABCD')\n",
    "#             X_transctrl, Y_transctrl, _ = dc.match_trials(transctrl_labeled_rsponses[tracing][locstr], stimulus_df, block='transition_control', trial_type='ABCD')\n",
    "#             X_randctrl_post, Y_randctrl_post, _ = dc.match_trials(randctrl_labeled_rsponses[tracing][locstr][1], stimulus_df, block='randomized_control_post', trial_type='ABCD')\n",
    "\n",
    "            X = X_oddball; Y = Y_oddball\n",
    "            nNeurons = X.shape[-1]\n",
    "            print(np.unique(Y,return_counts=True))\n",
    "#             pdb.set_trace()\n",
    "            #Use pseudopopulation vectors for decoding\n",
    "            confusion_mat, confusion_shf, confusion_z = dc.cross_validate(X_oddball,Y_oddball,Y_sort,method=method,nKfold=nKfold,classifier=classifier,clabels=[68, 78, 13, 26, 1])\n",
    "\n",
    "    #         fpath = os.path.join(SaveDir,'prevMSvsX_decoding_oddball-block_{}_{}.mat'.format(locstr,classifier))\n",
    "    #         with h5py.File(fpath,'w') as h5file:\n",
    "    #             h5file.create_dataset('confusion_mat',data=confusion_mat)\n",
    "    #             h5file.create_dataset('confusion_shf',data=confusion_shf)\n",
    "    #             h5file.create_dataset('confusion_z',data=confusion_z)\n",
    "    #             h5file.create_dataset('area',data=area)\n",
    "    #             h5file.create_dataset('classifier',data=classifier)\n",
    "    #             h5file.create_dataset('method',data=method)\n",
    "\n",
    "            dc.plot_decoding_accuracy(confusion_mat,confusion_z,class_labels=['A','B','C','D','X'],title=locstr,annot=True)\n",
    "            plt.suptitle('XABCD\\n {} {} nNeurons'.format(nNeurons,tracing))\n",
    "            plt.savefig(os.path.join(PlotDir,'nextMSvsX_decoding_oddball-blocks_{}-fold_{}-area_{}neurons.png'.format(nKfold,locstr,tracing)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
